{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5029c33d-d0b7-49a9-b7e6-a7f4b1ae847d",
   "metadata": {
    "collapsed": false,
    "name": "autogluon"
   },
   "source": [
    "# AutoML end-to-end with OpenFE and AutoGluon\n",
    "This example notebook uses [AutoGluon](https://auto.gluon.ai/dev/index.html) and the training dataset created from the Feature Store. \n",
    "\n",
    "The dataset based on the [Boston Housing Dataset](https://www.kaggle.com/code/prasadperera/the-boston-housing-dataset) and has features created by [OpenFE](https://openfe-document.readthedocs.io/en/latest/). \n",
    "\n",
    "This notebook creates a model to predict the median house value in neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279460f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNSUPPORTED BY SNOWFLAKE - CUSTOMER SUPPORTED ONLY\n",
    "\n",
    "# Copyright (c) 2025 Snowflake Inc. All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac55d7-6474-42c9-97d6-9863b836522f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "original_package_list"
   },
   "outputs": [],
   "source": [
    "# save a list of the current packages, so we can filter them out later when deploying\n",
    "!pip freeze > original_packages.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "install_packages"
   },
   "outputs": [],
   "source": [
    "# Install the AutoGluon packages\n",
    "!pip install autogluon --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_snowflake_session"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d1bcc-2979-477b-904b-80dd828f41d2",
   "metadata": {
    "language": "sql",
    "name": "show_training_available",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "show tables like 'DEMO_BOSTON_HOUSING_TRAINING_%';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf39989-da33-4005-8b53-0892781a838e",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "# input data for feature engineering\n",
    "table_name = 'DEMO_BOSTON_HOUSING_TRAINING'\n",
    "# feature to be predicted\n",
    "target_feature = 'medv'\n",
    "# unique / key column name\n",
    "feature_store_join_key = 'ID'\n",
    "# model name used for deployment\n",
    "model_name='BOSTON_MODEL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778160ff-abbe-4e89-bf2b-fa9dbc5cbd8f",
   "metadata": {
    "language": "python",
    "name": "cortex_setup"
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install snowflake-connector-python pandas --quiet\n",
    "\n",
    "# Use the new Container Services keypair authentication method\n",
    "from generateJWT import JWTGenerator\n",
    "\n",
    "# other supporting libraries\n",
    "from datetime import timedelta\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import requests\n",
    "import json\n",
    "\n",
    "account = '<org>-<account>'.upper()\n",
    "user = 'username'.upper()\n",
    "role = 'SPCS_ROLE'.upper()\n",
    "private_key_file_path = '/Users/rsa/rsa_key.p8'\n",
    "endpoint = '<generated-endpoint-name>.snowflakecomputing.app'\n",
    "endpoint_path = '/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf8325-21a4-431f-8c64-35ba7c14852d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "packge_imports"
   },
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import AutoGluon packages\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n",
    "\n",
    "# used for feature engineering\n",
    "from openfe import OpenFE, transform, tree_to_formula\n",
    "\n",
    "# used to creat train and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# for plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Snowflake feature store\n",
    "from snowflake.ml.feature_store import FeatureStore, FeatureView, Entity, CreationMode\n",
    "\n",
    "# helper to set entry details based on Notebook\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc99ea7-bcc2-4840-b030-9952a5bec2ea",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "read_data_from_snowflake"
   },
   "outputs": [],
   "source": [
    "# get data from Snowflake. This is a public dataset\n",
    "data = session.table(table_name).to_pandas()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5158b81-aeef-4627-af05-7ab2b23cf8c9",
   "metadata": {
    "collapsed": false,
    "name": "data_description"
   },
   "source": [
    "## Dataset Details\n",
    "Each record in the database describes a Boston suburb or town. The data was drawn from the Boston Standard Metropolitan Statistical Area (SMSA) in 1970.\n",
    "\n",
    "| **Name**    | **Description**                                                           |\n",
    "|---------|-----------------------------------------------------------------------|\n",
    "| CRIM    | per capita crime rate by town                                         |\n",
    "| ZN      | proportion of residential land zoned for lots over 25000 sq.ft.       |\n",
    "| INDUS   | proportion of non-retail business acres per town                      |\n",
    "| CHAS    | Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) |\n",
    "| NOX     | nitric oxides concentration (parts per 10 million)                    |\n",
    "| RM      | average number of rooms per dwelling                                  |\n",
    "| AGE     | proportion of owner-occupied units built prior to 1940                |\n",
    "| DIS     | weighted distances to five Boston employment centres                  |\n",
    "| RAD     | index of accessibility to radial highways                             |\n",
    "| TAX     | full-value property-tax rate per 10000usd                             |\n",
    "| PTRATIO | pupil-teacher ratio by town                                           |\n",
    "| LSTAT   | % lower status of the population                                      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6cd758-e9a1-496f-90d7-b2488821bb74",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "target_and_input_feaures"
   },
   "outputs": [],
   "source": [
    "# remove the join key from the data\n",
    "data.pop(feature_store_join_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973d06b-7758-4e6e-8feb-872e586650cd",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "train"
   },
   "outputs": [],
   "source": [
    "# using the engineered features and the data from Feature Store use AutoGluon to train a model\n",
    "model_path = 'tmp'\n",
    "predictor = TabularPredictor(label='medv', path=model_path).fit(data, time_limit=600 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45280f1-9db0-48f5-86e9-948dfbb1da3a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "evaluate"
   },
   "outputs": [],
   "source": [
    "# show the model results on the training data\n",
    "predictor.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716ea4e3-9dc5-4e52-a37a-fd104c93e7de",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "show_learning_curve"
   },
   "outputs": [],
   "source": [
    "# show the model learning curve\n",
    "predictor.learning_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994fe9e-ea82-4a6b-955c-dd61c0fd45a6",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "feature_importance_graph"
   },
   "outputs": [],
   "source": [
    "# graph the feature importance\n",
    "fimportance = predictor.feature_importance(data)\n",
    "fimportance = fimportance.sort_values('importance', ascending=True)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.barh(fimportance.index, fimportance['importance'])\n",
    "plt.title('Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204cd36-3cc4-4ec8-a53c-5d9401605ce3",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "feature_importance"
   },
   "outputs": [],
   "source": [
    "# sort the features by importance as a table\n",
    "fimportance.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f26dc10-c32d-43cc-816f-9b5376bf51cc",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "make_predictions"
   },
   "outputs": [],
   "source": [
    "# make prediction using the training data (so we can review the results compared to the actuals)\n",
    "y_pred = predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235dd7dd-878b-422b-8ff2-a84db5758367",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_results_with_new_features"
   },
   "outputs": [],
   "source": [
    "# merge the prediction with the original data using the index to ensure the correct prediction is matched with the correct row\n",
    "results = pd.merge(data, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1588d4a-8a65-4cd7-b935-7e95803571cf",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e21592-16bf-41a7-86e9-b11c8a066f79",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "show_results"
   },
   "outputs": [],
   "source": [
    "# show the results actual vs. predicted\n",
    "results[['medv_x','medv_y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b569ca-19c3-42b4-9820-8e4de4789082",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "prices_vs_predicted_graph"
   },
   "outputs": [],
   "source": [
    "# Visualizing the differences between actual prices and predicted values\n",
    "plt.scatter(results['medv_x'], results['medv_y'])\n",
    "plt.xlabel(\"Prices\")\n",
    "plt.ylabel(\"Predicted prices\")\n",
    "plt.title(\"Prices vs Predicted prices\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6cb39-dad4-475a-8523-f413b632ec4d",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "errors_graph"
   },
   "outputs": [],
   "source": [
    "# Checking Normality of errors\n",
    "sns.distplot(results['medv_x']-results['medv_y'])\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eba46e-9b79-4c16-98fd-f984a6367bd8",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "get_notebook_name"
   },
   "outputs": [],
   "source": [
    "# retrieve the notebook name as we will use it to name the feature store and deployment\n",
    "Notebook_name = os.environ.get('OBJECT_NAME', 'NOTEBOOK')\n",
    "Notebook_name = Notebook_name.replace(' ','_')\n",
    "print(Notebook_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d686be-ac71-49c5-b689-1f4e1e1cf9d1",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "show_best_model"
   },
   "outputs": [],
   "source": [
    "predictor.model_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5366cd-7bc4-44f6-b3ee-58f47ae5beda",
   "metadata": {
    "name": "model_registry"
   },
   "source": [
    "## Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2110b96f-53dd-405e-942e-81beb6ea35ac",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "get_model_registry_session"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml.model import custom_model\n",
    "from snowflake.ml.model import model_signature\n",
    "native_registry = Registry(session=session)\n",
    "\n",
    "model_name='BOSTON_MODEL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4d6e2-469e-4b6a-b306-a96eeb19e2cc",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "define_custom_model"
   },
   "outputs": [],
   "source": [
    "# as we are using a custom model we need to define the input and output schema\n",
    "class AutoGluonModel(custom_model.CustomModel):\n",
    "    def __init__(self, context: custom_model.ModelContext) -> None:\n",
    "        super().__init__(context)\n",
    "        context_path = self.context.path(\"model_dir\")\n",
    "        self.predictor = TabularPredictor.load(context_path, verbosity=4, require_version_match=False, require_py_version_match=False)\n",
    "    \n",
    "    @custom_model.inference_api\n",
    "    def predict(self, input_pdf: pd.DataFrame) -> pd.DataFrame:\n",
    "        import numpy as np\n",
    "        input_pdf['INPUT_DATA'] = input_pdf['INPUT_DATA'].map(json.loads)\n",
    "        fixed_input_pdf = pd.json_normalize(input_pdf['INPUT_DATA'])\n",
    "        input_dataset = TabularDataset(fixed_input_pdf)\n",
    "        output_np = self.predictor.predict(input_dataset)\n",
    "        output_np = np.where(np.isnan(output_np), None, output_np)\n",
    "        fixed_input_pdf['OUTPUT'] = output_np\n",
    "        fixed_input_pdf = fixed_input_pdf.fillna(np.nan).replace([np.nan], [None])\n",
    "        return fixed_input_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f5230-5108-4afc-86c1-6a56b4099261",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "autogluon_model_context"
   },
   "outputs": [],
   "source": [
    "# Create ModelContext that points to our model file\n",
    "autogluon_mc = custom_model.ModelContext(\n",
    "\tmodels={ # This should be for models that is supported by Model Registry\n",
    "\t},\n",
    "\tartifacts={ # Everything not supported needs to be here\n",
    "\t\t'model_dir': model_path+\"/\"\n",
    "\t}\n",
    ")\n",
    "\n",
    "autogluon_custom_model = AutoGluonModel(autogluon_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b988f0b7-4bf3-4991-b4a4-1061c96db48e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "define_local_predict"
   },
   "outputs": [],
   "source": [
    "# call predict on the model, if running using container notebooks this will use the model in the model_path\n",
    "def local_predict(input_pdf: pd.DataFrame) -> pd.DataFrame:\n",
    "    import numpy as np\n",
    "    input_pdf['INPUT_DATA'] = input_pdf['INPUT_DATA'].map(json.loads)\n",
    "    fixed_input_pdf = pd.json_normalize(input_pdf['INPUT_DATA'])\n",
    "    input_dataset = TabularDataset(fixed_input_pdf)\n",
    "    predictor = TabularPredictor.load(model_path+\"/\")\n",
    "    output_np = predictor.predict(input_dataset)\n",
    "    output_np = np.where(np.isnan(output_np), None, output_np)\n",
    "    fixed_input_pdf['OUTPUT'] = output_np\n",
    "    fixed_input_pdf = fixed_input_pdf.fillna(np.nan).replace([np.nan], [None])\n",
    "    return fixed_input_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6006101c-8944-4f45-a15e-7ed79bbf8065",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_test_dataframe"
   },
   "outputs": [],
   "source": [
    "# create a temporary table in Snowflake with the training data\n",
    "test_snowdf = session.write_pandas(train_f, table_name=\"temp_results\", table_type=\"temporary\", auto_create_table=True)\n",
    "\n",
    "test_snowdf\n",
    "\n",
    "from snowflake.snowpark import functions as F\n",
    "test_snowdf_cached1 = test_snowdf.na.fill(0).drop('OUTPUT').cache_result()\n",
    "test_snowdf_cached2 = test_snowdf_cached1.with_column('INPUT_DATA', F.to_varchar(F.object_construct_keep_null(F.col(\"*\"))))\\\n",
    "                     .select('INPUT_DATA').cache_result()\n",
    "test_pdf_for_mr = test_snowdf_cached2.limit(100).to_pandas()\n",
    "local_test_results_pdf = local_predict(test_pdf_for_mr.copy())\n",
    "predict_sign = model_signature.infer_signature(input_data=test_pdf_for_mr, output_data=local_test_results_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6f2e2-2b59-47b9-9a8a-4b3462bf7086",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "get_model_signature"
   },
   "outputs": [],
   "source": [
    "# this is the calling signature for the model\n",
    "predict_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db45ed6-c4d8-4a6a-969f-237c9203f2b2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "installed_packages"
   },
   "outputs": [],
   "source": [
    "# so the model can be deployed correctly we need to identify what additional packages are required \n",
    "!pip freeze > installed_packages.txt\n",
    "\n",
    "!diff -u0 original_packages.txt installed_packages.txt | grep -e \"^+[a-zA-Z]\" > new_packages.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a689061-8bae-4c84-afb1-d5d76a9c1061",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "list_of_additional_packages_for_spcs"
   },
   "outputs": [],
   "source": [
    "# create a list of the packages that are required\n",
    "with open('new_packages.txt') as f:\n",
    "    need = f.read().splitlines()\n",
    "\n",
    "packages_needed = [x.replace('+', '').replace(' ', '') for x in need ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815997ef-34d9-4724-8342-1e6253fcade7",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "log_custom_model_registry"
   },
   "outputs": [],
   "source": [
    "# register the model\n",
    "from snowflake.ml import version\n",
    "\n",
    "mv = native_registry.log_model(\n",
    "    autogluon_custom_model,\n",
    "    model_name=model_name,\n",
    "    pip_requirements=packages_needed,\n",
    "    signatures={\n",
    "        \"predict\": predict_sign\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54495e0-6f8c-44fb-bf82-84046c276a05",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "show_model_versions"
   },
   "outputs": [],
   "source": [
    "# get the model versions\n",
    "mr = native_registry.get_model(model_name)\n",
    "version_df = mr.show_versions()\n",
    "version_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a95ae1-a707-45a3-a68a-22691aa40e28",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "get_latest_model"
   },
   "outputs": [],
   "source": [
    "# get the latest version\n",
    "last_version_name = version_df['name'].iloc[-1]\n",
    "latest_version = mr.version(last_version_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e81829-ac50-465e-8035-6708d5579c1c",
   "metadata": {
    "name": "snowpark_container_services"
   },
   "source": [
    "## Snowpark Container Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2b897",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "# create a image repository \n",
    "create if not exists image repository DB.SERVICES.REPOSITORY;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5787a7a-ffbe-4f90-9baa-91c2c8c749a1",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "define_spcs_parameters"
   },
   "outputs": [],
   "source": [
    "# spcs deployment details\n",
    "compute_pool_name = \"my-compute-pool\"\n",
    "image_repo_name = f\"<database>.<schema>.<image-REPOSITORY-name>\"\n",
    "num_spcs_nodes = '1'\n",
    "spcs_instance_family = 'CPU_X64_M'\n",
    "service_name_without_namespace = 'INFERENCE_SERVICE'\n",
    "service_name = f'<database>.<schema>.{service_name_without_namespace}'\n",
    "print(service_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc5da18-99ad-4472-909a-a3860f65b4d0",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_compute_pool"
   },
   "outputs": [],
   "source": [
    "# create compute pool\n",
    "session.sql(f\"create compute pool if not exists {compute_pool_name} \\\n",
    "            min_nodes={num_spcs_nodes} \\\n",
    "            max_nodes={num_spcs_nodes} \\\n",
    "            instance_family={spcs_instance_family} \\\n",
    "            auto_resume=True \\\n",
    "            auto_suspend_secs=300\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3da72-ad23-4181-8a64-56d939673389",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "language": "python",
    "name": "create_service"
   },
   "outputs": [],
   "source": [
    "# create the service with the latest version of the model\n",
    "latest_version.create_service(service_name=service_name,\n",
    "                  service_compute_pool=compute_pool_name,\n",
    "                  image_repo=image_repo_name,\n",
    "                  build_external_access_integration=\"ALLOW_ALL_INTEGRATION\",\n",
    "                  max_instances=int(num_spcs_nodes),\n",
    "                  ingress_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfbe2dd-77dc-4348-b0e5-1dca5f9b9c7c",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "service_status"
   },
   "outputs": [],
   "source": [
    "# check the service is created and running\n",
    "session.sql(\"show services like '\"+service_name_without_namespace+\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0a166-b23c-400d-8ba2-5f6af4a6766e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "service_endpoint"
   },
   "outputs": [],
   "source": [
    "session.sql(\"show endpoints in service \"+service_name_without_namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c00477f-08ba-4529-bd5a-3f5d27f24b17",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "show_test_table"
   },
   "outputs": [],
   "source": [
    "# show test dataframe\n",
    "test_snowdf_cached2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955f7de1-fac8-413b-85c7-1407cf7f1c3e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "predict_on_test_data"
   },
   "outputs": [],
   "source": [
    "# make predictions using model deployed to SPCS\n",
    "start = time.time()\n",
    "service_predictions = latest_version.run(test_snowdf_cached2,function_name=\"predict\",\n",
    "                                         service_name=service_name_without_namespace).drop('INPUT_DATA')\n",
    "service_predictions.show()\n",
    "finish = time.time()\n",
    "print(\"Elapsed Seconds: \"+str(finish-start))\n",
    "print(\"Rows: \"+str(test_snowdf_cached2.count()))\n",
    "print(\"Columns: \"+str(len(service_predictions.columns)))\n",
    "test_snowdf_cached2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1420bd1e-f316-4e65-974e-d211d9f2b880",
   "metadata": {
    "collapsed": false,
    "name": "suspend_service"
   },
   "source": [
    "## Suspend the service and pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220297df-4832-4fbf-9983-7ffe659f07eb",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "suspend_service_compute_pool"
   },
   "outputs": [],
   "source": [
    "session.sql(\"alter service \"+service_name_without_namespace+\" suspend\")\n",
    "session.sql(\"alter compute pool \"+compute_pool_name+\" suspend\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "eric.gudgion@snowflake.com",
   "authorId": "367534575326",
   "authorName": "EGUDGION",
   "lastEditTime": 1740000544472,
   "notebookId": "hecaaq6opepgf3mcwufz",
   "sessionId": "340a5dd7-6d99-4733-97f5-0fc1daaa1d00"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
